{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "import pydot\n",
    "import statistics\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import FordFulkerson as ff\n",
    "import EdmondsKarp as EK\n",
    "from multiprocessing import Pool\n",
    "from collections import Counter\n",
    "from IPython.display import Image, display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"20%_test\"\n",
    "pathB = \"/home/achilleas/Desktop/thesis/DATASET F1/specimen_benign/20%_test\"\n",
    "pathT = \"80%_train\"\n",
    "paths = [\"/home/achilleas/Desktop/thesis/DATASET F1/Fold_\"+str(i) for i in range(1,6)]\n",
    "\n",
    "filename = \"default_G_tone_map\"\n",
    "mapFilename = \"default_unique_mapping\"\n",
    "\n",
    "rootDirs = {}\n",
    "trainDirs = {}\n",
    "\n",
    "for i in range(len(paths)):\n",
    "    p = [os.path.join(root, name)\n",
    "             for root, dirs, files in os.walk(paths[i]+\"/\"+path)\n",
    "             for name in files\n",
    "             if name.endswith(filename+\".csv\")]\n",
    "    p.sort()\n",
    "    rootDirs[i] = p\n",
    "\n",
    "benignDir = [os.path.join(root, name)\n",
    "             for root, dirs, files in os.walk(pathB)\n",
    "             for name in files\n",
    "             if name.endswith(filename+\".csv\")]\n",
    "benignDir.sort()\n",
    "\n",
    "for i in range(len(paths)):\n",
    "    trainDir = [os.path.join(root, name)\n",
    "                 for root, dirs, files in os.walk(paths[i]+\"/\"+pathT)\n",
    "                 for name in files\n",
    "                 if name.endswith(filename+\".csv\")]\n",
    "    trainDir.sort()\n",
    "    trainDirs[i] = trainDir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = {\"ACCESS_MASK\":0,\"Atom\":1,\"BOOLEAN\":2,\"Debug\":3,\"Device\":4,\n",
    "                                 \"Environment\":5,\"File\":6,\"HANDLE\":7,\"Job\":8,\"LONG\":9,\"LPC\":10,\n",
    "                                 \"Memory\":11,\"NTSTATUS\":12,\"Object\":13,\"Other\":14,\"PHANDLE\":15,\n",
    "                                 \"PLARGE_INTEGER\":16,\"Process\":17,\"PUNICODE_STRING\":18,\n",
    "                                 \"PULONG\":19,\"PULARGE_INTEGER\":20,\"PVOID_SIZEAFTER\":21,\n",
    "                                 \"PWSTR\":22,\"Registry\":23,\"Security\":24,\"Synchronization\":25,\n",
    "                                 \"Time\":26,\"Transaction\":27,\"ULONG\":28,\"WOW64\":29, \"DummyStart\":30,\"DummyEnd\":31}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getSourceSink(path):\n",
    "    verteces = []\n",
    "    with open(path) as fp:\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            verteces.append(line.split(\",\"))\n",
    "            line = fp.readline()\n",
    "    return [verteces[0][0],verteces[-1][1].strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getArray (path):\n",
    "    results = []\n",
    "    with open(path) as csvfile:\n",
    "        reader = csv.reader(csvfile,csv.QUOTE_NONNUMERIC) # change contents to floats\n",
    "        for row in reader: # each row is a list\n",
    "            nums = []\n",
    "            for i in row: \n",
    "                if i :\n",
    "                    nums.append(int(i))\n",
    "            results.append(nums)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def createExtendedG(g):\n",
    "    parents = []\n",
    "    children = []\n",
    "    for i in range(len(g)):\n",
    "        for j in range(len(g[i])):\n",
    "            if g[i][j]!=0:\n",
    "                break\n",
    "            else:\n",
    "                children.append(i)\n",
    "    for i in range(len(g)):\n",
    "        for j in range(len(g[i])):\n",
    "            if g[j][i]!=0:\n",
    "                break\n",
    "            else:\n",
    "                parents.append(i)\n",
    "                \n",
    "    for i in range(len(g)):\n",
    "        g[i].append(0)\n",
    "        g[i].append(0)\n",
    "    leng= len(g)\n",
    "    g.append([0 for i in range (leng+2)])\n",
    "    g.append([0 for i in range (leng+2)])\n",
    "    \n",
    "    for i in children :\n",
    "        g[i][-1] = 1\n",
    "    for j in parents:\n",
    "        g[-2][j]=1\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def createImage(g):\n",
    "    G = pydot.Dot(graph_type='digraph')\n",
    "    for i in range(len(g)):\n",
    "        x = pydot.Node(i)\n",
    "        for j in range(len(g[i])):\n",
    "            if g[i][j]!= 0 :\n",
    "                y = pydot.Node(j)\n",
    "                e = pydot.Edge(i,j)\n",
    "                G.add_edge(e)\n",
    "                \n",
    "    im = Image(G.create_png())\n",
    "#     G.write_png(path)\n",
    "    display(im)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def findMaxOutDegreeVertex(g):\n",
    "    outDegrees={}\n",
    "    return_matrix = []\n",
    "    for i in range(len(g)):\n",
    "        for j in range(len(g[i])):\n",
    "            if g[i][j]!=0:\n",
    "                if i not in outDegrees:\n",
    "                    outDegrees[i]=[g[i][j],1]\n",
    "                else: \n",
    "                    weight = outDegrees[i][0]+g[i][j]\n",
    "                    cardinality = outDegrees[i][1]+1\n",
    "                    outDegrees[i]=[weight,cardinality]\n",
    "    return outDegrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def findMaxInDegreeVertex(g):\n",
    "    inDegrees= {}\n",
    "    return_matrix = []\n",
    "    for i in range (len(g)):\n",
    "        for j in range(len(g[i])):\n",
    "            if g[j][i]!=0:\n",
    "                if i not in inDegrees:\n",
    "                    inDegrees[i] = [g[j][i],1]\n",
    "                else: \n",
    "                    weight = inDegrees[i][0]+g[j][i]\n",
    "                    cardinality = inDegrees[i][1]+1\n",
    "                    inDegrees[i]=[weight,cardinality]\n",
    "                    \n",
    "    return inDegrees    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def createCoverageGraph(g):\n",
    "    cvg = []\n",
    "    combinedDegrees = {}\n",
    "    inDegrees = findMaxInDegreeVertex(g)\n",
    "    inKeys =list(inDegrees.keys())\n",
    "    outDegrees = findMaxOutDegreeVertex(g)\n",
    "    outKeys =list(outDegrees.keys())\n",
    "    combinedDegrees= outDegrees.copy()\n",
    "    for i in inKeys:\n",
    "        if i in outDegrees:\n",
    "            combinedDegrees[i] = [inDegrees[i][0]+outDegrees[i][0], inDegrees[i][1]+outDegrees[i][1]]\n",
    "        else : \n",
    "            combinedDegrees[i] = inDegrees[i]\n",
    "    sortedcDegrees = sorted(combinedDegrees.items(), key = lambda kv:kv[0])     \n",
    "    cKeys = [i[0] for i in sortedcDegrees]\n",
    "    for i in range(30):\n",
    "        row = [0 for k in range(30)]\n",
    "        if i not in cKeys:\n",
    "            cvg.append(row)\n",
    "            continue\n",
    "        weight = combinedDegrees[i][0]\n",
    "        cardinality = combinedDegrees[i][1]\n",
    "        for j in cKeys:\n",
    "            if weight > combinedDegrees[j][0] and cardinality > combinedDegrees[j][1]:\n",
    "                row[j] = 1\n",
    "        cvg.append(row)\n",
    "        \n",
    "\n",
    "    return cvg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def writeCSV()\n",
    "generic method to quickly write a graph to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def writeCSV(g,path,name):\n",
    "    path_spl = path.split('/')\n",
    "    path_spl[-1] = name\n",
    "    sp_path = '/'.join(path_spl)\n",
    "    with open(sp_path, mode='w') as cvg_file:\n",
    "        cvg_writer = csv.writer(cvg_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for i in g:\n",
    "            cvg_writer.writerow(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def executeTrial ()\n",
    "## here we call the max Flow algorithm \n",
    "### Max flow in GRG\n",
    "* if we get the source and the sink from the default G' the algorithm stops in cases of first caller X and last called X function.\n",
    "* if we get the source and the sink from the default G_tone_cardinality tests show that nothing stops the algorithm as in all cases the first caller is different than the last called\n",
    "\n",
    "### Max flow in CVG\n",
    "* the algorithm works fine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def executeTrial(path):\n",
    "    sp_path = path.split('/')\n",
    "    family = sp_path[-3]\n",
    "    graph = getArray(path)\n",
    "#     for i in range(len(graph)):\n",
    "#         for j in range(len(graph[i])):\n",
    "#             if graph[i][j]!=0:\n",
    "#                 graph[i][j] =1\n",
    "#     g = Graph(createExtendedG(createCoverageGraph(graph)))\n",
    "    sp_path[-1]= \"default_G_tone_cardinality.txt\"\n",
    "#     source = 30\n",
    "#     sink = 31\n",
    "    source = classes[getSourceSink('/'.join(sp_path))[0]]\n",
    "    sink = classes[getSourceSink('/'.join(sp_path))[1]]\n",
    "    fG = Graph(graph).FordFulkerson(source,sink)\n",
    "    return [fG, family]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def experiment()\n",
    "wrapper method to execute and calculate median max flow for each member of our dataset\n",
    "## median\n",
    "we prefer median values of the flows because they are more robust to individual extreme flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def experiment(dirs):\n",
    "#     print(len(dirs))\n",
    "    max_flow_vals={}\n",
    "    mean_max_flow={}\n",
    "    mean_flows = []\n",
    "    total_values = []\n",
    "    for i in dirs:\n",
    "        values= executeTrial(i)\n",
    "        total_values.append(values[0])\n",
    "        if values[1] in max_flow_vals:\n",
    "            max_flow_vals[values[1]].append(values[0])\n",
    "        else : \n",
    "            max_flow_vals[values[1]]= [values[0]]\n",
    "\n",
    "    for i in max_flow_vals:\n",
    "        mean_max_flow[i] = statistics.median(max_flow_vals[i])\n",
    "    for i in mean_max_flow :\n",
    "        mean_flows.append(mean_max_flow[i])\n",
    "        \n",
    "    return mean_max_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main body \n",
    "here we make separate calls in our functions to test the validity of the above methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def executeExp():\n",
    "    root_flows = experiment(rootDir)\n",
    "    benign_flows = experiment(benignDir)\n",
    "    train_flows = experiment(trainDir)\n",
    "    # mal_corners = [min(root_flows), max(root_flows)]\n",
    "    # benign_corners = [min(benign_flows), max(benign_flows)]\n",
    "\n",
    "\n",
    "    # print(\"mal_corners:\")\n",
    "    # print(mal_corners)\n",
    "    # print(\"benign_corners:\")\n",
    "    # print(benign_corners)\n",
    "\n",
    "    sort_root = sorted(root_flows.items(), key = lambda kv:kv[1])\n",
    "    sort_benign = sorted(benign_flows.items(), key = lambda kv:kv[1])\n",
    "    sort_train = sorted(train_flows.items(), key = lambda kv:kv[1])\n",
    "\n",
    "    # print()\n",
    "\n",
    "    sort_root_vals = [i[1] for i in sort_root]\n",
    "    sort_benign_vals = [i[1] for i in sort_benign]\n",
    "    sort_train_vals = [i[1] for i in sort_train]\n",
    "\n",
    "\n",
    "    sort_root_names = [i[0] for i in sort_root]\n",
    "    sort_benign_names = [i[0] for i in sort_benign]\n",
    "    sort_train_names = [i[0] for i in sort_train]\n",
    "\n",
    "\n",
    "    sorted_root_flows = sorted(root_flows)\n",
    "    sorted_benign_flows= sorted(benign_flows)\n",
    "\n",
    "\n",
    "\n",
    "    # bCount =sorted(Counter(benign_flows).items(),key = lambda kv:kv[0])\n",
    "    # mCount = sorted(Counter(root_flows).items(),key = lambda kv:kv[0])\n",
    "\n",
    "\n",
    "\n",
    "    # --------------------------------------------\n",
    "    lists = [sort_root_vals, sort_benign_vals,sort_train_vals]\n",
    "    names = [sort_root_names, sort_benign_names, sort_train_names]\n",
    "\n",
    "    for i in lists:\n",
    "        plt.plot(i,marker=11)\n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "    plt.draw()\n",
    "\n",
    "    fig.savefig('maxFlow.png')\n",
    "    #---------------------------------------------------\n",
    "    # executeTrial(rootDir[0])\n",
    "    # ar = [[0,1,1,1,1],\n",
    "    #       [0,0,0,1,1],\n",
    "    #       [0,0,0,1,1],\n",
    "    #       [0,0,0,0,1],\n",
    "    #       [0,0,0,0,0]]\n",
    "    # createExtendedG(ar)\n",
    "    # cvg = createCoverageGraph(getArray(rootDir[0]),rootDir[0])\n",
    "\n",
    "    # for i in rootDir:\n",
    "    #     writeCSV(createExtendedG(createCoverageGraph(getArray(i))),i, 'CVGB.csv')\n",
    "    # for i in cvg:\n",
    "    #     print(i)\n",
    "    # g = createExtendedG(ar)\n",
    "    # G = pydot.Dot(graph_type='digraph')\n",
    "    # for i in range(len(g)):\n",
    "    #     x = pydot.Node(i)\n",
    "    #     for j in range(len(g[i])):\n",
    "    #         if g[i][j]!= 0 :\n",
    "    #             y = pydot.Node(j)\n",
    "    #             e = pydot.Edge(i,j)\n",
    "    #             G.add_edge(e)\n",
    "\n",
    "    # im = Image(G.create_png())\n",
    "    # display(im)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow map\n",
    "## def createFlowMap(g):\n",
    "* Given the capacity of each edge and the neighbors of each node of a graph, the function returns a NxN array tha represents the flow map of the given graph, having in each `g'[i][j]= MaxFlow(cap,neighs,i,j)`. **the base function used to permutate our original GrGs** \n",
    "\n",
    "## def createMap(dirs):\n",
    "* wrapper method that calls createFlowMap(path) for every path in the dirs list. This method is used to run through the rootDir, benignDir and train Dir to create our point of reference\n",
    "\n",
    "## def CSM(A,B):\n",
    "* calculates the cosine similarity metric for two arrays A and B\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def createFlowMap(capacity, neighbors): \n",
    "    values = [[0 for i in range(len(capacity))] for j in range(len(capacity))]\n",
    "\n",
    "    for i in range(len(capacity)):\n",
    "        for j in range(len(capacity)):\n",
    "            values[i][j] = EK.EdmondsKarp(capacity,neighbors,i,j)\n",
    "#     return values\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def createMap(paths):\n",
    "    maps ={}\n",
    "    median_vals = {}\n",
    "    for i in range(len(paths)):\n",
    "        family = paths[i].split('/')[-3]\n",
    "        cap, neigh = EK.ParseGraph(paths[i])\n",
    "        map_values = createFlowMap(cap,neigh)\n",
    "        if family in maps:\n",
    "            maps[family].append(map_values)\n",
    "        else :\n",
    "            maps[family] =  [map_values]\n",
    "        printProgressBar(i, len(paths))       \n",
    "    \n",
    "    return maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CSM(A,B):\n",
    "    e = sum(A[i][j]*B[i][j] for i in range(len(A)) for j in range(len(B)))\n",
    "    a = sum(A[i][j]**2 for i in range(len(A))for j in range(len(A)))\n",
    "    b = sum(B[i][j]**2 for i in range(len(B))for j in range(len(B)))\n",
    "    d = math.sqrt(a)*math.sqrt(b)\n",
    "    return round(e/d,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDatabase(dirs, db):\n",
    "    total = {}\n",
    "    for i in range(len(dirs)):\n",
    "        csm_val ={}\n",
    "        fname = dirs[i].split('/')[-3]\n",
    "        cap , neigh = EK.ParseGraph(dirs[i])\n",
    "        A = createFlowMap(cap,neigh)\n",
    "        for d in db:\n",
    "            val = []\n",
    "            for g in db[d]:\n",
    "                val.append(CSM(A,g))\n",
    "            csm_val[d] = max(val)\n",
    "        printProgressBar(i,len(dirs))\n",
    "        sr = sorted(csm_val.items(), key = lambda kv:kv[1], reverse =True)\n",
    "        total[i]=[fname, sr[0][0], sr[0][1]]\n",
    "#         print([i, fname, sr[0][0], sr[0][1]])\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = {}\n",
    "#     for t in test:\n",
    "#         for r in train:\n",
    "#             csm_vals= {}\n",
    "#             for i in range(len(test[t])):\n",
    "#                 vals =[]\n",
    "#                 for j in range(len(train[r])):\n",
    "#                     vals.append(CSM(test[t][i],train[r][j]))\n",
    "#                 csm_vals[t]=vals\n",
    "#         total[t]= sorted(csm_vals[t], reverse = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 database created███████████████████████████████████████████████████████████████████████████████████-| 100.0% \n",
      "1 database created███████████████████████████████████████████████████████████████████████████████████-| 100.0% \n",
      "2 database created███████████████████████████████████████████████████████████████████████████████████-| 100.0% \n",
      "3 database created███████████████████████████████████████████████████████████████████████████████████-| 100.0% \n",
      "4 database created███████████████████████████████████████████████████████████████████████████████████-| 100.0% \n",
      "5\n"
     ]
    }
   ],
   "source": [
    "database = []\n",
    "for i in range(len(paths)):\n",
    "    database.append(createMap(trainDirs[i]))\n",
    "    print(\"%d database created\"%(i))\n",
    "print(len(database))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |███████████████████████████████████████████████████████████████████████████████████████████████████-| 99.8% \n",
      "malcheck 0 done.\n",
      "check 0 mal check finished in 1385.261115 \n",
      " |█████████████████████████████████████████████████████████████████████████████████████████████████---| 97.1% \n",
      "Bencheck 0 done.\n",
      "check 0 ben check finished in 88.375573 s\n",
      " |███████████████████████████████████████████████████████████████████████████████████████████████████-| 99.8% \n",
      "malcheck 1 done.\n",
      "check 1 mal check finished in 1337.751143 \n",
      " |█████████████████████████████████████████████████████████████████████████████████████████████████---| 97.1% \n",
      "Bencheck 1 done.\n",
      "check 1 ben check finished in 76.439063 s\n",
      " |███████████████████████████████████████████████████████████████████████████████████████████████████-| 99.8% \n",
      "malcheck 2 done.\n",
      "check 2 mal check finished in 1144.466473 \n",
      " |█████████████████████████████████████████████████████████████████████████████████████████████████---| 97.1% \n",
      "Bencheck 2 done.\n",
      "check 2 ben check finished in 76.589894 s\n",
      " |███████████████████████████████████████████████████████████████████████████████████████████████████-| 99.8% \n",
      "malcheck 3 done.\n",
      "check 3 mal check finished in 1242.105242 \n",
      " |█████████████████████████████████████████████████████████████████████████████████████████████████---| 97.1% \n",
      "Bencheck 3 done.\n",
      "check 3 ben check finished in 89.135211 s\n",
      " |███████████████████████████████████████████████████████████████████████████████████████████████████-| 99.8% \n",
      "malcheck 4 done.\n",
      "check 4 mal check finished in 1347.029598 \n",
      " |█████████████████████████████████████████████████████████████████████████████████████████████████---| 97.1% \n",
      "Bencheck 4 done.\n",
      "check 4 ben check finished in 89.446226 s\n"
     ]
    }
   ],
   "source": [
    "malCheck = []\n",
    "for i in range(len(paths)):\n",
    "    ti = time.time()\n",
    "    malCheck.append(checkDatabase(rootDirs[i], database[i]))\n",
    "    print(\"\\nmalcheck %d done.\"%(i))\n",
    "    # with open('malwareCheck.txt', 'w') as f:\n",
    "    #     for item in malwareCheck:\n",
    "    #         f.write(\"%s\\n\" % malwareCheck[item])\n",
    "    # f.close()\n",
    "    print(\"check %d mal check finished in %f \"%(i,time.time()-ti))\n",
    "    ti = time.time()\n",
    "    benignCheck = checkDatabase(benignDir, database[i])\n",
    "    print(\"\\nBencheck %d done.\"%(i)) \n",
    "    # with open('benignCheck.txt', 'w') as f:\n",
    "    #     for item in benignCheck:\n",
    "    #         f.write(\"%s\\n\" % benignCheck[item])\n",
    "    # f.close()\n",
    "    print(\"check %d ben check finished in %f s\"%(i, time.time()-ti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityMetric(sr):\n",
    "    counterA = 0\n",
    "    counterB = 0\n",
    "    counterC = 0\n",
    "    for i in sr :\n",
    "        A,B = i[0].split(',')[0], i[0].split(',')[1]\n",
    "        C,D = i[1].split(',')[0], i[1].split(',')[1]\n",
    "        if A==C and B==D:\n",
    "            counterA +=1\n",
    "        if A==C or B==D:\n",
    "            counterB +=1\n",
    "        if A==C or A==D or B == C or B == D:\n",
    "            counterC += 1\n",
    "    print(\"cA = %d (%f) cB= %d (%f) cC =%d (%f)\"%(counterA, counterA/len(sr), counterB, counterB/len(sr), counterC, counterC/len(sr)))\n",
    "    return [counterA/len(sr),counterB/len(sr),counterC/len(sr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveFigures(mal_th, ben_th, start):\n",
    "    lists = [mal_th,ben_th]\n",
    "    v = 0\n",
    "    for i in range(len(mal_th)):\n",
    "        v = max(v,abs(mal_th[i]-ben_th[i]))\n",
    "\n",
    "    print(v)\n",
    "\n",
    "    for i in lists:\n",
    "        plt.plot(i,marker= 11)\n",
    "    plt.legend([\"True positives\",\"False positives\"])\n",
    "    plt.yticks(np.arange(0, 1, 0.05))\n",
    "    plt.xticks(np.arange(0,step, 1))\n",
    "    plt.ylabel(\"\")\n",
    "    plt.draw()\n",
    "    plt.savefig(str(start)+\".png\")\n",
    "    plt.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cA = 346 (0.664107) cB= 420 (0.806142) cC =425 (0.815739)\n",
      "cA = 346 (0.664107) cB= 419 (0.804223) cC =426 (0.817658)\n",
      "cA = 343 (0.658349) cB= 415 (0.796545) cC =425 (0.815739)\n",
      "cA = 340 (0.652591) cB= 412 (0.790787) cC =427 (0.819578)\n",
      "cA = 332 (0.627599) cB= 414 (0.782609) cC =423 (0.799622)\n",
      "[[0.6641074856046065, 0.6641074856046065, 0.6583493282149712, 0.6525911708253359, 0.6275992438563327], [0.8061420345489443, 0.8042226487523992, 0.7965451055662188, 0.7907869481765835, 0.782608695652174], [0.8157389635316699, 0.817658349328215, 0.8157389635316699, 0.8195777351247601, 0.7996219281663516]]\n",
      "------------------\n",
      "[0.6533509428211706, 0.796061086539264, 0.8136671879365333]\n"
     ]
    }
   ],
   "source": [
    "mal_pairs = []\n",
    "sr = []\n",
    "avg = [[] for i in range(3)]\n",
    "for i in range(len(malCheck)):\n",
    "    mal_pairs.append([malCheck[i][j] for j in malCheck[i]])\n",
    "    \n",
    "for i in range(len(mal_pairs)):\n",
    "    sr.append(sorted(mal_pairs[i],key =lambda kv:kv[-1],reverse=True))\n",
    "    \n",
    "ben_pairs = [benignCheck[i] for i in benignCheck]\n",
    "br = sorted(ben_pairs,key =lambda kv:kv[-1],reverse=True)\n",
    "sims = [similarityMetric(i) for i in sr]\n",
    "for i in range(len(sims)):\n",
    "    for j in range(len(sims[i])):\n",
    "        avg[j].append(sims[i][j])\n",
    "res = [statistics.mean(avg[i]) for i in range(len(avg)) ]\n",
    "print(avg)\n",
    "print(\"------------------\")\n",
    "print()\n",
    "# c =0\n",
    "# # # m_vals =[sr[i][-1] for i in range(len(sr))]\n",
    "# b_vals = [br[i][-1] for i in range(len(br))]\n",
    "# for i in sr :\n",
    "#     print(i)\n",
    "# print(\"--------------------------\")\n",
    "# for j in br :\n",
    "#     if j[-1] > 0.8059138664157343 :\n",
    "#         c+=1\n",
    "#     print(j)\n",
    "# print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'list' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-9d70ba81e8cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;31m#mal_th[i]+=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mCM\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'list' and 'float'"
     ]
    }
   ],
   "source": [
    "# start = 0.855737150150311\n",
    "for j in br:\n",
    "    start =j[-1]\n",
    "    step = 10\n",
    "    dif = 1.0 - start\n",
    "    thresh = [0 for i in range(step)]\n",
    "    for i in range(step):\n",
    "        thresh[i] = start + i*(dif/step)\n",
    "    mal_th = [0 for i in range(len(thresh))]\n",
    "    ben_th = [0 for i in range(len(thresh))]\n",
    "    for i in range(len(thresh)):\n",
    "        CM=0\n",
    "        val=0\n",
    "        for j in range(len(sr)):\n",
    "            if sr[j][-1] > thresh[i]:\n",
    "                #mal_th[i]+=1\n",
    "                CM += 1\n",
    "        val=CM/521\n",
    "        mal_th[i] = val\n",
    "\n",
    "    for i in range(len(thresh)):\n",
    "        CM=0\n",
    "        val=0\n",
    "        for j in range(len(br)):\n",
    "            if br[j][-1] > thresh[i]:\n",
    "                #mal_th[i]+=1\n",
    "                CM += 1\n",
    "        val=CM/35\n",
    "        ben_th[i] = val\n",
    "    # print(mal_th)\n",
    "    print(ben_th)\n",
    "    saveFigures(mal_th,ben_th,start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
