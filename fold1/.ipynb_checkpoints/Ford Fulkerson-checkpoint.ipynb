{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "import pydot\n",
    "import statistics\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "from IPython.display import Image, display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = \"/home/achilleas/Desktop/thesis/DATASET F1/Fold_1/20%_test\"\n",
    "pathB = \"/home/achilleas/Desktop/thesis/DATASET F1/specimen_benign/20%_test\"\n",
    "pathT = \"/home/achilleas/Desktop/thesis/DATASET F1/Fold_1/80%_train\"\n",
    "\n",
    "# filename = \"default_G_tone_UNIQUES_map\"\n",
    "filename = \"default_G_tone_map\"\n",
    "# filename = \"CVGB\"\n",
    "grgFilename = \"default_G'\"\n",
    "mapFilename = \"default_unique_mapping\"\n",
    "rootDir = [os.path.join(root, name)\n",
    "             for root, dirs, files in os.walk(path)\n",
    "             for name in files\n",
    "             if name.endswith(filename+\".csv\")]\n",
    "rootDir.sort()\n",
    "benignDir = [os.path.join(root, name)\n",
    "             for root, dirs, files in os.walk(pathB)\n",
    "             for name in files\n",
    "             if name.endswith(filename+\".csv\")]\n",
    "benignDir.sort()\n",
    "trainDir = [os.path.join(root, name)\n",
    "             for root, dirs, files in os.walk(pathT)\n",
    "             for name in files\n",
    "             if name.endswith(filename+\".csv\")]\n",
    "trainDir.sort()\n",
    "\n",
    "grgDir = [os.path.join(root,name)\n",
    "             for root, dirs, files in os.walk(path)\n",
    "             for name in files\n",
    "             if name.endswith(grgFilename+\".txt\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classes = {\"ACCESS_MASK\":0,\"Atom\":1,\"BOOLEAN\":2,\"Debug\":3,\"Device\":4,\n",
    "                                 \"Environment\":5,\"File\":6,\"HANDLE\":7,\"Job\":8,\"LONG\":9,\"LPC\":10,\n",
    "                                 \"Memory\":11,\"NTSTATUS\":12,\"Object\":13,\"Other\":14,\"PHANDLE\":15,\n",
    "                                 \"PLARGE_INTEGER\":16,\"Process\":17,\"PUNICODE_STRING\":18,\n",
    "                                 \"PULONG\":19,\"PULARGE_INTEGER\":20,\"PVOID_SIZEAFTER\":21,\n",
    "                                 \"PWSTR\":22,\"Registry\":23,\"Security\":24,\"Synchronization\":25,\n",
    "                                 \"Time\":26,\"Transaction\":27,\"ULONG\":28,\"WOW64\":29, \"DummyStart\":30,\"DummyEnd\":31}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Python program for implementation of Ford Fulkerson algorithm \n",
    "\n",
    "\n",
    "#This class represents a directed graph using adjacency matrix representation \n",
    "class Graph: \n",
    "\n",
    "    def __init__(self,graph): \n",
    "        self.graph = graph # residual graph \n",
    "        self. ROW = len(graph) \n",
    "        #self.COL = len(gr[0]) \n",
    "        \n",
    "\n",
    "    '''Returns true if there is a path from source 's' to sink 't' in \n",
    "    residual graph. Also fills parent[] to store the path '''\n",
    "    \n",
    "    def isReachable(self, s, d):\n",
    "        # Mark all the vertices as not visited \n",
    "        visited =[False]*(self.ROW) \n",
    "        # Create a queue for BFS \n",
    "        queue=[] \n",
    "        \n",
    "        # Mark the source node as visited and enqueue it \n",
    "        queue.append(s) \n",
    "        visited[s] = True\n",
    "\n",
    "        while queue:\n",
    "            #Dequeue a vertex from queue  \n",
    "            n = queue.pop(0) \n",
    "            \n",
    "            # If this adjacent node is the destination node, \n",
    "            # then return true \n",
    "            if n == d: \n",
    "                return True\n",
    "\n",
    "            #  Else, continue to do BFS \n",
    "            \n",
    "            for ind, val in enumerate(self.graph[n]): \n",
    "                if visited[ind] == False and val > 0 : \n",
    "                    queue.append(ind) \n",
    "                    visited[ind] = True\n",
    "        # If BFS is complete without visited d \n",
    "        return False\n",
    "        \n",
    "    def BFS(self,s, t, parent): \n",
    "        \n",
    "        # Mark all the vertices as not visited \n",
    "        visited =[False]*(self.ROW) \n",
    "        \n",
    "        # Create a queue for BFS \n",
    "        queue=[] \n",
    "        \n",
    "        # Mark the source node as visited and enqueue it \n",
    "        queue.append(s) \n",
    "        visited[s] = True\n",
    "        \n",
    "        # Standard BFS Loop \n",
    "        while queue: \n",
    "\n",
    "            #Dequeue a vertex from queue and print it \n",
    "            u = queue.pop(0) \n",
    "\n",
    "            # Get all adjacent vertices of the dequeued vertex u \n",
    "            # If a adjacent has not been visited, then mark it \n",
    "            # visited and enqueue it \n",
    "            for ind, val in enumerate(self.graph[u]): \n",
    "                if visited[ind] == False and val > 0 : \n",
    "                    queue.append(ind) \n",
    "                    visited[ind] = True\n",
    "                    parent[ind] = u \n",
    "        # If we reached sink in BFS starting from source, then return \n",
    "        # true, else false \n",
    "        return True if visited[t] else False\n",
    "\n",
    "\n",
    "    # Returns tne maximum flow from s to t in the given graph \n",
    "    def FordFulkerson(self, source, sink): \n",
    "        # This array is filled by BFS and to store path \n",
    "        parent = [-1]*(self.ROW) \n",
    "\n",
    "        max_flow = 0 # There is no flow initially \n",
    "\n",
    "        if not self.isReachable(source,sink):\n",
    "            return -1\n",
    "        # Augment the flow while there is path from source to sink \n",
    "        while self.BFS(source, sink, parent) : \n",
    "\n",
    "            # Find minimum residual capacity of the edges along the \n",
    "            # path filled by BFS. Or we can say find the maximum flow \n",
    "            # through the path found. \n",
    "            path_flow = float(\"Inf\") \n",
    "            s = sink \n",
    "            while(s != source): \n",
    "                path_flow = min (path_flow, self.graph[parent[s]][s]) \n",
    "                s = parent[s] \n",
    "            # Add path flow to overall flow \n",
    "            max_flow += path_flow \n",
    "\n",
    "            # update residual capacities of the edges and reverse edges \n",
    "            # along the path \n",
    "            v = sink \n",
    "            while(v != source): \n",
    "                u = parent[v] \n",
    "                self.graph[u][v] -= path_flow \n",
    "                self.graph[v][u] += path_flow \n",
    "                v = parent[v] \n",
    "#         print (\"max flow is: \"+str(max_flow))\n",
    "        return max_flow\n",
    "\n",
    "\n",
    "# # Create a graph given in the above diagram \n",
    "\n",
    "# graph = [[0, 16, 13, 0, 0, 0], \n",
    "# \t\t[0, 0, 10, 12, 0, 0], \n",
    "# \t\t[0, 4, 0, 0, 14, 0], \n",
    "# \t\t[0, 0, 9, 0, 0, 20], \n",
    "# \t\t[0, 0, 0, 7, 0, 4], \n",
    "# \t\t[0, 0, 0, 0, 0, 0]] \n",
    "\n",
    "# g = Graph(graph) \n",
    "\n",
    "# source = 0; sink = 5\n",
    "\n",
    "# print (\"The maximum possible flow is %d \" % g.FordFulkerson(source, sink)) \n",
    "\n",
    "# #This code is contributed by Neelam Yadav \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Bfs(C, F, s, t):  # C is the capacity matrix\n",
    "    n = len(C)\n",
    "    queue = []\n",
    "    queue.append(s)\n",
    "    global level\n",
    "    level = n * [0]  # initialization\n",
    "    level[s] = 1  \n",
    "    while queue:\n",
    "        k = queue.pop(0)\n",
    "        for i in range(n):\n",
    "                if (F[k][i] < C[k][i]) and (level[i] == 0): # not visited\n",
    "                        level[i] = level[k] + 1\n",
    "                        queue.append(i)\n",
    "    return level[t] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Dfs(C, F, k, cp):\n",
    "    tmp = cp\n",
    "    if k == len(C)-1:\n",
    "        return cp\n",
    "    for i in range(len(C)):\n",
    "        if (level[i] == level[k] + 1) and (F[k][i] < C[k][i]):\n",
    "            f = Dfs(C,F,i,min(tmp,C[k][i] - F[k][i]))\n",
    "            F[k][i] = F[k][i] + f\n",
    "            F[i][k] = F[i][k] - f\n",
    "            tmp = tmp - f\n",
    "    return cp - tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def MaxFlow(C,s,t):\n",
    "    n = len(C)\n",
    "    F = [n*[0] for i in range(n)] # F is the flow matrix\n",
    "    flow = 0\n",
    "    while(Bfs(C,F,s,t)):\n",
    "           flow = flow + Dfs(C,F,s,100000)\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getSourceSink(path):\n",
    "    verteces = []\n",
    "    with open(path) as fp:\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            verteces.append(line.split(\",\"))\n",
    "            line = fp.readline()\n",
    "    return [verteces[0][0],verteces[-1][1].strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getArray (path):\n",
    "    results = []\n",
    "    with open(path) as csvfile:\n",
    "        reader = csv.reader(csvfile,csv.QUOTE_NONNUMERIC) # change contents to floats\n",
    "        for row in reader: # each row is a list\n",
    "            nums = []\n",
    "            for i in row: \n",
    "                if i :\n",
    "                    nums.append(int(i))\n",
    "            results.append(nums)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def createExtendedG(g):\n",
    "    parents = []\n",
    "    children = []\n",
    "    for i in range(len(g)):\n",
    "        for j in range(len(g[i])):\n",
    "            if g[i][j]!=0:\n",
    "                break\n",
    "            else:\n",
    "                children.append(i)\n",
    "    for i in range(len(g)):\n",
    "        for j in range(len(g[i])):\n",
    "            if g[j][i]!=0:\n",
    "                break\n",
    "            else:\n",
    "                parents.append(i)\n",
    "                \n",
    "    for i in range(len(g)):\n",
    "        g[i].append(0)\n",
    "        g[i].append(0)\n",
    "    leng= len(g)\n",
    "    g.append([0 for i in range (leng+2)])\n",
    "    g.append([0 for i in range (leng+2)])\n",
    "    \n",
    "    for i in children :\n",
    "        g[i][-1] = 1\n",
    "    for j in parents:\n",
    "        g[-2][j]=1\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def createImage(g,path):\n",
    "    G = pydot.Dot(graph_type='digraph')\n",
    "    for i in range(len(g)):\n",
    "        x = pydot.Node(i)\n",
    "        for j in range(len(g[i])):\n",
    "            if g[i][j]!= 0 :\n",
    "                y = pydot.Node(j)\n",
    "                e = pydot.Edge(i,j)\n",
    "                G.add_edge(e)\n",
    "                \n",
    "    im = Image(G.create_png())\n",
    "    G.write_png(path)\n",
    "    display(im)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def findMaxOutDegreeVertex(g):\n",
    "    outDegrees={}\n",
    "    return_matrix = []\n",
    "    for i in range(len(g)):\n",
    "        for j in range(len(g[i])):\n",
    "            if g[i][j]!=0:\n",
    "                if i not in outDegrees:\n",
    "                    outDegrees[i]=[g[i][j],1]\n",
    "                else: \n",
    "                    weight = outDegrees[i][0]+g[i][j]\n",
    "                    cardinality = outDegrees[i][1]+1\n",
    "                    outDegrees[i]=[weight,cardinality]\n",
    "    return outDegrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def findMaxInDegreeVertex(g):\n",
    "    inDegrees= {}\n",
    "    return_matrix = []\n",
    "    for i in range (len(g)):\n",
    "        for j in range(len(g[i])):\n",
    "            if g[j][i]!=0:\n",
    "                if i not in inDegrees:\n",
    "                    inDegrees[i] = [g[j][i],1]\n",
    "                else: \n",
    "                    weight = inDegrees[i][0]+g[j][i]\n",
    "                    cardinality = inDegrees[i][1]+1\n",
    "                    inDegrees[i]=[weight,cardinality]\n",
    "                    \n",
    "    return inDegrees    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def createCoverageGraph(g):\n",
    "    cvg = []\n",
    "    combinedDegrees = {}\n",
    "    inDegrees = findMaxInDegreeVertex(g)\n",
    "    inKeys =list(inDegrees.keys())\n",
    "    outDegrees = findMaxOutDegreeVertex(g)\n",
    "    outKeys =list(outDegrees.keys())\n",
    "    combinedDegrees= outDegrees.copy()\n",
    "    for i in inKeys:\n",
    "        if i in outDegrees:\n",
    "            combinedDegrees[i] = [inDegrees[i][0]+outDegrees[i][0], inDegrees[i][1]+outDegrees[i][1]]\n",
    "        else : \n",
    "            combinedDegrees[i] = inDegrees[i]\n",
    "    sortedcDegrees = sorted(combinedDegrees.items(), key = lambda kv:kv[0])     \n",
    "    cKeys = [i[0] for i in sortedcDegrees]\n",
    "    for i in range(30):\n",
    "        row = [0 for k in range(30)]\n",
    "        if i not in cKeys:\n",
    "            cvg.append(row)\n",
    "            continue\n",
    "        weight = combinedDegrees[i][0]\n",
    "        cardinality = combinedDegrees[i][1]\n",
    "        for j in cKeys:\n",
    "            if weight > combinedDegrees[j][0] and cardinality > combinedDegrees[j][1]:\n",
    "                row[j] = 1\n",
    "        cvg.append(row)\n",
    "        \n",
    "\n",
    "    return cvg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def writeCSV()\n",
    "generic method to quickly write a graph to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def writeCSV(g,path,name):\n",
    "    path_spl = path.split('/')\n",
    "    path_spl[-1] = name\n",
    "    sp_path = '/'.join(path_spl)\n",
    "    with open(sp_path, mode='w') as cvg_file:\n",
    "        cvg_writer = csv.writer(cvg_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for i in g:\n",
    "            cvg_writer.writerow(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def executeTrial ()\n",
    "## here we call the max Flow algorithm \n",
    "### Max flow in GRG\n",
    "* if we get the source and the sink from the default G' the algorithm stops in cases of first caller X and last called X function.\n",
    "* if we get the source and the sink from the default G_tone_cardinality tests show that nothing stops the algorithm as in all cases the first caller is different than the last called\n",
    "\n",
    "### Max flow in CVG\n",
    "* the algorithm works fine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def executeTrial(path):\n",
    "    sp_path = path.split('/')\n",
    "    family = sp_path[-3]\n",
    "    graph = getArray(path)\n",
    "#     for i in range(len(graph)):\n",
    "#         for j in range(len(graph[i])):\n",
    "#             if graph[i][j]!=0:\n",
    "#                 graph[i][j] =1\n",
    "#     g = Graph(createExtendedG(createCoverageGraph(graph)))\n",
    "    sp_path[-1]= \"default_G_tone_cardinality.txt\"\n",
    "#     source = 30\n",
    "#     sink = 31\n",
    "    source = classes[getSourceSink('/'.join(sp_path))[0]]\n",
    "    sink = classes[getSourceSink('/'.join(sp_path))[1]]\n",
    "    fG = Graph(graph).FordFulkerson(source,sink)\n",
    "    return [fG, family]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def experiment()\n",
    "wrapper method to execute and calculate median max flow for each member of our dataset\n",
    "## median\n",
    "we prefer median values of the flows because they are more robust to individual extreme flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def experiment(dirs):\n",
    "#     print(len(dirs))\n",
    "    max_flow_vals={}\n",
    "    mean_max_flow={}\n",
    "    mean_flows = []\n",
    "    total_values = []\n",
    "    for i in dirs:\n",
    "        values= executeTrial(i)\n",
    "        total_values.append(values[0])\n",
    "        if values[1] in max_flow_vals:\n",
    "            max_flow_vals[values[1]].append(values[0])\n",
    "        else : \n",
    "            max_flow_vals[values[1]]= [values[0]]\n",
    "\n",
    "    for i in max_flow_vals:\n",
    "        mean_max_flow[i] = statistics.median(max_flow_vals[i])\n",
    "    for i in mean_max_flow :\n",
    "        mean_flows.append(mean_max_flow[i])\n",
    "        \n",
    "    return mean_max_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main body \n",
    "here we make separate calls in our functions to test the validity of the above methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def executeExp():\n",
    "    root_flows = experiment(rootDir)\n",
    "    benign_flows = experiment(benignDir)\n",
    "    train_flows = experiment(trainDir)\n",
    "    # mal_corners = [min(root_flows), max(root_flows)]\n",
    "    # benign_corners = [min(benign_flows), max(benign_flows)]\n",
    "\n",
    "\n",
    "    # print(\"mal_corners:\")\n",
    "    # print(mal_corners)\n",
    "    # print(\"benign_corners:\")\n",
    "    # print(benign_corners)\n",
    "\n",
    "    sort_root = sorted(root_flows.items(), key = lambda kv:kv[1])\n",
    "    sort_benign = sorted(benign_flows.items(), key = lambda kv:kv[1])\n",
    "    sort_train = sorted(train_flows.items(), key = lambda kv:kv[1])\n",
    "\n",
    "    # print()\n",
    "\n",
    "    sort_root_vals = [i[1] for i in sort_root]\n",
    "    sort_benign_vals = [i[1] for i in sort_benign]\n",
    "    sort_train_vals = [i[1] for i in sort_train]\n",
    "\n",
    "\n",
    "    sort_root_names = [i[0] for i in sort_root]\n",
    "    sort_benign_names = [i[0] for i in sort_benign]\n",
    "    sort_train_names = [i[0] for i in sort_train]\n",
    "\n",
    "\n",
    "    sorted_root_flows = sorted(root_flows)\n",
    "    sorted_benign_flows= sorted(benign_flows)\n",
    "\n",
    "\n",
    "\n",
    "    # bCount =sorted(Counter(benign_flows).items(),key = lambda kv:kv[0])\n",
    "    # mCount = sorted(Counter(root_flows).items(),key = lambda kv:kv[0])\n",
    "\n",
    "\n",
    "\n",
    "    # --------------------------------------------\n",
    "    lists = [sort_root_vals, sort_benign_vals,sort_train_vals]\n",
    "    names = [sort_root_names, sort_benign_names, sort_train_names]\n",
    "\n",
    "    for i in lists:\n",
    "        plt.plot(i,marker=11)\n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "    plt.draw()\n",
    "\n",
    "    fig.savefig('maxFlow.png')\n",
    "    #---------------------------------------------------\n",
    "    # executeTrial(rootDir[0])\n",
    "    # ar = [[0,1,1,1,1],\n",
    "    #       [0,0,0,1,1],\n",
    "    #       [0,0,0,1,1],\n",
    "    #       [0,0,0,0,1],\n",
    "    #       [0,0,0,0,0]]\n",
    "    # createExtendedG(ar)\n",
    "    # cvg = createCoverageGraph(getArray(rootDir[0]),rootDir[0])\n",
    "\n",
    "    # for i in rootDir:\n",
    "    #     writeCSV(createExtendedG(createCoverageGraph(getArray(i))),i, 'CVGB.csv')\n",
    "    # for i in cvg:\n",
    "    #     print(i)\n",
    "    # g = createExtendedG(ar)\n",
    "    # G = pydot.Dot(graph_type='digraph')\n",
    "    # for i in range(len(g)):\n",
    "    #     x = pydot.Node(i)\n",
    "    #     for j in range(len(g[i])):\n",
    "    #         if g[i][j]!= 0 :\n",
    "    #             y = pydot.Node(j)\n",
    "    #             e = pydot.Edge(i,j)\n",
    "    #             G.add_edge(e)\n",
    "\n",
    "    # im = Image(G.create_png())\n",
    "    # display(im)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow map\n",
    "## def createFlowMap(g):\n",
    "* given a graph `g` it returns a new graph `g'` where instead of the `g[i][j]` representing the weight of the edge from i to j it represents the max flow there is in the path that connects the two verteces.\n",
    "\n",
    "## def createMedianMap(list_of_g):\n",
    "* given a list of flow graphs that are part of the same family, `L_G` it return a new `G'` where every `G[i][j]` is the median max_flow of the `g_1,..,k` graphs of the `L_G`\n",
    "   `in other words for each i,j in G': G'[i][j] = median(L_G_1[i,j],L_G_2[i,j]..,L_G_k[i,j]) for k = len(L_G)`\n",
    "\n",
    "## def createMap(dirs):\n",
    "* wrapper method that calls createFlowMap(path) for every path in the dirs list. This method is used to run through the rootDir, benignDir and train Dir to create our point of reference\n",
    "\n",
    "## def CSM(A,B):\n",
    "* calculates the cosine similarity metric for two arrays A and B\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFlowMap(g): \n",
    "    values = [[0 for i in range(len(g))] for j in range(len(g))]\n",
    "    graph = Graph(g)\n",
    "    for i in range(len(g)):\n",
    "        for j in range(len(g[i])):\n",
    "            if i!=j:\n",
    "                values[i][j] = graph.FordFulkerson(i,j)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMedianMap(list_of_g):\n",
    "    x = [[[]for i in range(len(list_of_g[0]))] for k in range(len(list_of_g[0]))]\n",
    "    median_map = [[0 for i in range(len(list_of_g[0]))] for k in range(len(list_of_g[0]))]\n",
    "    for g in list_of_g:\n",
    "        for i in range(len(g)):\n",
    "            for j in range(len(g[i])):\n",
    "                x[i][j].append(g[i][j])\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x[i])):\n",
    "            median_map[i][j] = statistics.median(x[i][j])\n",
    "    return median_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMap(paths):\n",
    "    maps ={}\n",
    "    median_vals = {}\n",
    "    for i in paths:\n",
    "        family = i.split('/')[-3]\n",
    "        map_values = createFlowMap(getArray(i))\n",
    "        if family in maps:\n",
    "            maps[family].append(map_values)\n",
    "        else :\n",
    "            maps[family] =  [map_values]\n",
    "    \n",
    "    for m in maps:\n",
    "        median_vals[m] = createMedianMap(maps[m])\n",
    "    return median_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSM(A,B):\n",
    "    enumerator = 0\n",
    "    denominator = 0\n",
    "    a = 0\n",
    "    b = 0 \n",
    "    for i in range(len(A)):\n",
    "        for j in range(len(B)):\n",
    "            enumerator += A[i][j]*B[i][j]\n",
    "            a += (A[i][j]**2)\n",
    "            b += (B[i][j]**2)\n",
    "    denominator = math.sqrt(a)*math.sqrt(b)\n",
    "    if denominator != 0 :\n",
    "        return enumerator/denominator\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben = createMap(trainDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "you had a precision of : 0.339731\n",
      "counter was : 177\n"
     ]
    }
   ],
   "source": [
    "csm_vals = {}\n",
    "counter = 0\n",
    "for i in range(len(rootDir)):\n",
    "    test = createFlowMap(getArray(rootDir[i]))\n",
    "    for b in ben:\n",
    "        csm_vals[b] = CSM(ben[b],test)\n",
    "    sr = sorted(csm_vals.items(), key =lambda kv:kv[1],reverse = True)\n",
    "    print(i)\n",
    "    if (sr[0][0] == rootDir[i].split('/')[-3]) :\n",
    "        counter+=1\n",
    "#     print([sr[0],rootDir[i].split('/')[-3]])\n",
    "print (\"you had a precision of : %f\"%(counter/len(rootDir)))\n",
    "print( \"counter was : %d\"%(counter))\n",
    "# a = np.array(train)\n",
    "# print(a)\n",
    "\n",
    "\n",
    "# car = [[1,2,2,2,2],\n",
    "#        [10,1,2,1,1],\n",
    "#        [1,3,0,12,1],\n",
    "#        [1,2,3,0,1],\n",
    "#        [19,2,1,2,0]]\n",
    "# v = Graph(ar)\n",
    "\n",
    "# train = createFlowMap([ar,var])\n",
    "# arrs = []\n",
    "# for i in train:\n",
    "#     a = np.array(i,dtype=object)\n",
    "#     print(a)\n",
    "# test = np.array(createFlowMap([car]),dtype=object)\n",
    "\n",
    "\n",
    "# for i in range(len(g)):\n",
    "#     for j in range(len(g[i])):\n",
    "#         print (g[i][j])\n",
    "#     print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
